{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -q kokoro>=0.3.4 soundfile\n"
      ],
      "metadata": {
        "id": "P5xI8sawZfcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kokoro import KPipeline\n",
        "import soundfile as sf\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipeline = KPipeline(lang_code='a')  # 'a' for American English\n",
        "\n",
        "# Text to convert\n",
        "text = \"\"\"Introducing DeepSeek R1—where advanced AI research meets next-level language modeling! At its core, DeepSeek R1 fuses a state-of-the-art transformer architecture with an innovative dynamic retrieval module. This unique hybrid structure is engineered to combine deep contextual understanding with rapid, real-time memory retrieval. Each deep contextual layer has been meticulously designed to capture nuanced language patterns, while an efficient attention mechanism prioritizes critical data. Coupled with dynamic memory integration, this model processes complex queries with remarkable precision. Extensive benchmarking on datasets such as SQuAD and GLUE confirms that DeepSeek R1 not only achieves exceptional language comprehension and generation but also offers significantly reduced latency—ideal for real-time applications. Detailed ablation studies underpin its design, revealing that every component—from deep contextual layers to dynamic memory retrieval—plays a critical role. This rigorous testing ensures that no element is redundant, optimizing performance for both research and practical deployment. Engineered with scalability in mind, DeepSeek R1 is not just a laboratory marvel. Its architecture is robust enough to power next-generation chatbots, intelligent search engines, and advanced content creation tools—bridging the gap between theoretical excellence and practical application. DeepSeek R1 isn’t merely an incremental improvement; it’s a paradigm shift that sets new benchmarks for AI research and commercial applications. Its comprehensive design promises to inspire future innovations and redefine what’s possible in natural language processing.\"\"\"\n",
        "\n",
        "# Generate audio for the entire text\n",
        "generator = pipeline(\n",
        "    text,\n",
        "    voice='af_heart',\n",
        "    speed=1.0\n",
        ")\n",
        "\n",
        "# Collect audio data from all segments\n",
        "audio_data = []\n",
        "for i, (_, _, audio) in enumerate(generator):\n",
        "    audio_data.append(audio)\n",
        "\n",
        "# Concatenate all audio segments\n",
        "final_audio = []\n",
        "for segment in audio_data:\n",
        "    final_audio.extend(segment)\n",
        "\n",
        "# Save the complete audio to a single file\n",
        "sf.write('speech_complete.wav', final_audio, 24000)"
      ],
      "metadata": {
        "id": "U8A75IHYdwOS",
        "outputId": "eda4875e-000b-4d40-b927-0a31faecb38c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "\u001b[32m16:29:04\u001b[0m | \u001b[36m        pipeline:90\u001b[0m | \u001b[33m\u001b[1m WARNING\u001b[0m | \u001b[33m\u001b[1mEspeakFallback not Enabled: OOD words will be skipped\u001b[0m\n",
            "\u001b[32m16:29:04\u001b[0m | \u001b[36m        pipeline:91\u001b[0m | \u001b[33m\u001b[1m WARNING\u001b[0m | \u001b[33m\u001b[1m{'espeak not installed on your system'}\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GNBXc4l4fnXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}