You can control how many tokens the model generates by setting a maximum length. This helps you avoid long or off-topic answers and also manage costs.