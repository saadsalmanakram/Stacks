# Tree of Thoughts (ToT)

## Overview
Tree of Thoughts (ToT) is a framework designed to enhance the problem-solving capabilities of Large Language Models (LLMs) by introducing structured exploration of intermediate steps. Unlike simple prompting methods, ToT allows LLMs to evaluate and backtrack through intermediate thoughts using tree search algorithms like Breadth-First Search (BFS), Depth-First Search (DFS), and Beam Search.

ToT is particularly useful for complex tasks requiring strategic lookahead, such as mathematical reasoning, logical inference, and multi-step planning. The framework was introduced by Yao et al. (2023) and Long (2023) and has shown significant improvements over conventional prompting techniques.

---

## Key Concepts

### 1. Thoughts as Intermediate Steps
In ToT, **thoughts** represent coherent sequences of text generated by the LLM that serve as intermediate steps toward solving a problem. These thoughts can be evaluated, selected, and expanded systematically.

### 2. Search Algorithms in ToT
ToT employs tree search algorithms to navigate through thoughts:
- **Breadth-First Search (BFS):** Explores all thoughts at the current depth before proceeding to the next level.
- **Depth-First Search (DFS):** Explores as far as possible along one branch before backtracking.
- **Beam Search:** Selects the top `b` candidates at each level to maintain efficiency.

### 3. Self-Evaluation and Lookahead
At each step, the LLM evaluates its generated thoughts using a scoring mechanism. For example, in the **Game of 24** task, thoughts are classified as **"sure"**, **"maybe"**, or **"impossible"** based on their likelihood of reaching the solution.

### 4. ToT Controller (Reinforcement Learning Approach)
Long (2023) introduced an alternative approach where a **ToT Controller**, trained via reinforcement learning (RL), dynamically adjusts search strategies like backtracking depth and exploration-exploitation tradeoffs.

---

## Implementation

### 1. Installing Dependencies
To use ToT in Python, install the required dependencies:

```bash
pip install openai numpy networkx
```

### 2. Implementing a Simple Tree of Thoughts Model
Below is an original Python implementation of ToT using BFS for problem-solving:

```python
import openai
import networkx as nx
import random

def generate_thoughts(prompt, num_candidates=3):
    """Generate multiple thought candidates based on the given prompt."""
    thoughts = []
    for _ in range(num_candidates):
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "system", "content": "Think step-by-step."},
                      {"role": "user", "content": prompt}]
        )
        thoughts.append(response["choices"][0]["message"]["content"])
    return thoughts

def evaluate_thought(thought):
    """Evaluate the thought using a heuristic scoring mechanism."""
    if "impossible" in thought.lower():
        return -1  # Discard
    elif "sure" in thought.lower():
        return 1   # High confidence
    else:
        return 0   # Uncertain, keep exploring

def tree_of_thoughts_solver(initial_prompt, max_depth=3):
    """Perform BFS to explore the best solution using ToT."""
    G = nx.DiGraph()
    G.add_node(0, text=initial_prompt)
    queue = [(0, 0)]  # (Node ID, Depth)
    node_id = 1

    while queue:
        parent, depth = queue.pop(0)
        if depth >= max_depth:
            continue

        thoughts = generate_thoughts(G.nodes[parent]['text'])
        for thought in thoughts:
            score = evaluate_thought(thought)
            if score == -1:
                continue
            G.add_node(node_id, text=thought)
            G.add_edge(parent, node_id)
            queue.append((node_id, depth + 1))
            node_id += 1
    
    return G

# Example Usage
initial_prompt = "Find the best way to reach 24 using 8, 3, 3, and 1"
solution_tree = tree_of_thoughts_solver(initial_prompt)
```

---

## Applications of Tree of Thoughts

### 1. **Mathematical Reasoning**
- Used in tasks like the **Game of 24**, where ToT breaks problems into solvable subproblems.

### 2. **Logical Deduction and Puzzle Solving**
- Helps in structured reasoning for solving Sudoku, logic riddles, and proof-based problems.

### 3. **Coding and Algorithmic Problem Solving**
- Assists in debugging, code generation, and algorithm optimization.

### 4. **Decision Making and Planning**
- Useful in AI-driven strategic games and real-world decision-making tasks.

---

## Future Enhancements
1. **Reinforcement Learning-based ToT Controller**
   - Implement adaptive tree search strategies for different problem domains.
2. **Hybrid Search Mechanisms**
   - Combine BFS, DFS, and RL-based controllers for optimal efficiency.
3. **PanelGPT Integration**
   - Extend ToT with multi-agent collaboration using PanelGPT.

---

## References
- Yao et al. (2023). "Tree of Thoughts: Deliberate Problem Solving with Language Models."
- Long (2023). "Reinforcement Learning-Driven Tree Search Strategies for LLMs."
- Sun (2023). "PanelGPT: Collaborative LLM Decision-Making."


# Also check this repo:
- https://github.com/kyegomez/tree-of-thoughts

---

