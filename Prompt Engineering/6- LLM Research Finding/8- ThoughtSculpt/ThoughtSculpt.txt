Reasoning with Intermediate Revision and Search for LLMs

Chi et al. (2024) introduce a new approach to improve reasoning and search tasks that can be broken down into smaller parts.

Their method, called THOUGHTSCULPT, is a graph-based system that lets language models (LLMs) revise and connect different thoughts step-by-step.

Unlike other methods like Tree-of-thoughts (which organizes ideas in a tree structure), THOUGHTSCULPT uses a strategy called Monte Carlo Tree Search (MCTS) to explore ideas more effectively.

In this system, a "thought evaluator" reviews and gives feedback on partial ideas. Meanwhile, a "thought generator" creates new possible solutions. Together, they refine and improve the current idea, acting as the "expansion phase."

Finally, a "decision simulator" (part of the MCTS process) runs through different thoughts to see which one could lead to the best outcome.

Because it constantly refines ideas, THOUGHTSCULPT is great for open-ended tasks like creative problem solving and multi-step reasoning.

This approach could lead to more advanced reasoning abilities for LLMs and better ways to handle complex tasks. It's worth keeping an eye on this research as it could shape future developments in AI reasoning.